import pandas, mlbgid, matplotlib, numpy, sys, urllib2, datetime, re, csv
from pandas import DataFrame
from pylab import *
import matplotlib.pyplot as plt
from matplotlib.path import Path
from matplotlib.patches import PathPatch
from collections import defaultdict
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
import sqlite3
import xml.dom.minidom


conn = sqlite3.connect('baseball.db')
c = conn.cursor()
c.execute('''CREATE TABLE game_ststs(Batter TEXT, Event TEXT, Balls TEXT)''')
conn.commit()


def get_game_id(*dates):
#construct a base url and add list dates in a loop
	baseURL = 'http://gd2.mlb.com/components/game/mlb/year_'
	for date in dates:
		year, month, day = date[0:4], date[5:7], date[8:10]
		fullurl = baseURL + year + '/month_' + month + '/day_' + day + '/'
#using the dates to find each individual game id for the date and populate a tuple
		g_id = []
		g_id = [a.text.strip()[4:-1] for a in BeautifulSoup(urllib2.urlopen(fullurl)).find_all('li',text=re.compile("gid_"))]
		for g in g_id:
			game_id_url = baseURL + g[0:4] + '/month_' + g[5:7] + '/day_' + g[8:10] + '/gid_' + g + '/inning/inning_all.xml'
			data = ET.parse(urllib2.urlopen(game_id_url))
			try:
				for baseball_stats in data.findall('inning/top/atbat'):
					event_number = baseball_stats.attrib['num']
					event_play = baseball_stats.attrib['event']
					des = baseball_stats.attrib['des']
					c.execute('''INSERT INTO game_stats (Batter, Event, Balls) VALUES(?,?,?)''',(event_number,event_play,des))
			except:
				print None

def create_db_populate(get_game_id,db_creation):
	get_game_id('2014_05_04','2014_05_03')
	db_creation
	with conn:
		for i in get_game_id:
			print i

def db_creation():
	conn = sqlite3.connect('baseball.db')
	c = conn.cursor()
	c.execute('''CREATE TABLE game_ststs(Batter TEXT, Event TEXT, Balls TEXT)''')
	
	
get_game_id('2014_05_04','2014_05_03')
