import pandas, mlbgid, matplotlib, numpy, sys, urllib2, datetime, re, csv
from pandas import DataFrame
from pylab import *
import matplotlib.pyplot as plt
from matplotlib.path import Path
from matplotlib.patches import PathPatch
from collections import defaultdict
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
import sqlite3
import xml.dom.minidom




def get_game_id(*dates):
	conn = sqlite3.connect('baseball.db')
	curs = conn.cursor()
	curs.execute('''CREATE TABLE game_stats(Batter TEXT, Event TEXT, Balls TEXT)''')
	conn.commit()
#construct a base url and add list dates in a loop
	baseURL = 'http://gd2.mlb.com/components/game/mlb/year_'
	for date in dates:
		year, month, day = date[0:4], date[5:7], date[8:10]
		fullurl = baseURL + year + '/month_' + month + '/day_' + day + '/'
#using the dates to find each individual game id for the date and populate a tuple
		g_id = []
		g_id = [a.text.strip()[4:-1] for a in BeautifulSoup(urllib2.urlopen(fullurl)).find_all('li',text=re.compile("gid_"))]
		for g in g_id:
			game_id_url = baseURL + g[0:4] + '/month_' + g[5:7] + '/day_' + g[8:10] + '/gid_' + g + '/inning/inning_all.xml'
			data = ET.parse(urllib2.urlopen(game_id_url))
			try:
				for baseball_stats in data.findall('inning/top/atbat'):
					event_number = baseball_stats.attrib['num']
					event_play = baseball_stats.attrib['event']
					des = baseball_stats.attrib['des']
					curs.execute('INSERT INTO game_stats VALUES(?,?,?)',(event_number,event_play,des))
					conn.commit()
					print baseball_stats
			except:
				print None

def create_db_populate(get_game_id,db_creation):
	get_game_id('2014_05_03','2014_05_04','2014_05_05','2014_05_06','2014_05_07','2014_05_08','2014_05_09''2014_05_10','2014_05_11','2014_05_12','2014_05_13','2014_05_14')
	db_creation
	with conn:
		for i in get_game_id:
			print i
	
	
get_game_id('2014_05_03','2014_05_04','2014_05_05','2014_05_06','2014_05_07','2014_05_08','2014_05_09''2014_05_10','2014_05_11','2014_05_12','2014_05_13','2014_05_14')
